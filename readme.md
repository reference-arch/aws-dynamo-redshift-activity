#RedshiftCopyActivityFromDynamoDBTable Sample 

This sample demonstrates how you can use Data Pipeline's RedshiftCopyActivity to copy data from a DynamoDB table to a Redshift table.  This sample was motivated by a use case that requires the user to provide AWS credentials to access the DynamoDB table.  It is assumed that the owner of the DynamoDB table has granted the user read access to the table.  To make this sample to work, you must ensure you have the following:

* Connection string for the destination Redshift cluster, e.g. jdbc:redshift://_hostname_:5439/_database_
* Redshift database name
* Redshift username and password.  This user must have write access to the table where data will be copied to.
* DynamoDB table name.  Note that both the table name and column names must match on both sides of the copy.
* AWS credentials, i.e the access key and the secret key, to access the DynamoDB table.
* DynamoDB table read ratio.
* S3 location to direct log messages generated by Data Pipeline.  

You will need to provide the above information in the "put-pipeline-definition" command below.

##Running this sample

```sh
 $> aws datapipeline create-pipeline --name redshift_copy_from_dynamodb_pipeline --unique-id redshift_copy_from_dynamodb_pipeline 

# You receive a pipeline activity like this. 
#   -----------------------------------------
#   |             CreatePipeline             |
#   +-------------+--------------------------+
#   |  pipelineId |  df-0554887H4KXKTY59MRJ  |
#   +-------------+--------------------------+

#now upload the pipeline definition 

  $> aws datapipeline put-pipeline-definition --pipeline-id df-0554887H4KXKTY59MRJ \
  --pipeline-definition file://samples/RedshiftCopyActivitySample/RedshiftCopyActivitySample.json \
  --parameter-values myConnectionString=<connection_string> myRedshiftDatabase=<database> \
  myRedshiftUsername=<username> myRedshiftPassword=<password> \
  myScript="copy <table_name> from 'dynamodb://<table_name>' credentials 'aws_access_key_id=<your_access_key>;aws_secret_access_key=<your_secret_key>' readratio <ratio>;" \
 myLogUri="<your_log_dir>"

# You receive a validation messages like this

#   ----------------------- 
#   |PutPipelineDefinition|
#   +-----------+---------+
#   |  errored  |  False  |
#   +-----------+---------+

#now activate the pipeline
  $> aws datapipeline activate-pipeline --pipeline-id df-0554887H4KXKTY59MRJ


#check the status of your pipeline 

  >$ aws datapipeline list-runs --pipeline-id df-0554887H4KXKTY59MRJ
#       Name                                                Scheduled Start      Status                 
#       ID                                                  Started              Ended              
#---------------------------------------------------------------------------------------------------
#   1.  ActivityId_vmVn4                                    2015-11-06T23:52:04  WAITING_FOR_RUNNER     
#       @ActivityId_vmVn4_2015-11-06T23:52:04               2015-11-06T23:52:11                     
#
#   2.  ResourceId_idL0Y                                    2015-11-06T23:52:04  CREATING               
#       @ResourceId_idL0Y_2015-11-06T23:52:04               2015-11-06T23:52:11      
```

##Related documentation
https://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/dp-object-redshiftcopyactivity.html

